"""
RAGç³»ç»Ÿé›†æˆæµ‹è¯•
æµ‹è¯•å…ˆè¿›RAGç³»ç»Ÿçš„ç«¯åˆ°ç«¯åŠŸèƒ½
"""

import pytest
import asyncio
import tempfile
import os
from typing import List, Dict, Any

from app.rag.advanced_rag import AdvancedRAGSystem, create_advanced_rag_system
from app.services.rag_service import RAGService
from app.core.config import Settings


class MockSettings(Settings):
    """æµ‹è¯•ç”¨æ¨¡æ‹Ÿé…ç½®"""
    vector_store_type: str = "chromadb"
    enable_graph_retrieval: bool = True
    enable_advanced_reranking: bool = True
    enable_query_expansion: bool = True


@pytest.fixture
async def rag_system():
    """RAGç³»ç»Ÿæµ‹è¯•å¤¹å…·"""
    system = await create_advanced_rag_system(
        vector_store_type="chromadb",
        enable_graph_retrieval=False,  # ç®€åŒ–æµ‹è¯•ï¼Œç¦ç”¨å›¾æ£€ç´¢
        enable_advanced_reranking=False,  # ç®€åŒ–æµ‹è¯•ï¼Œç¦ç”¨é‡æ’åº
        enable_query_expansion=False   # ç®€åŒ–æµ‹è¯•ï¼Œç¦ç”¨æŸ¥è¯¢æ‰©å±•
    )
    yield system
    await system.shutdown()


@pytest.fixture
async def rag_service():
    """RAGæœåŠ¡æµ‹è¯•å¤¹å…·"""
    settings = MockSettings()
    service = RAGService(settings)
    await service.startup()
    yield service
    await service.shutdown()


@pytest.fixture
def sample_documents():
    """ç¤ºä¾‹æ–‡æ¡£"""
    return [
        {
            "id": "doc_1",
            "content": "äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚è¯¥é¢†åŸŸçš„ç ”ç©¶åŒ…æ‹¬æœºå™¨äººã€è¯­è¨€è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¸“å®¶ç³»ç»Ÿç­‰ã€‚",
            "filename": "ai_intro.txt",
            "doc_type": "text",
            "metadata": {"category": "technology", "language": "zh"}
        },
        {
            "id": "doc_2", 
            "content": "Machine Learning is a subset of artificial intelligence that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. It focuses on the development of computer programs that can access data and use it to learn for themselves.",
            "filename": "ml_intro.txt",
            "doc_type": "text",
            "metadata": {"category": "technology", "language": "en"}
        },
        {
            "id": "doc_3",
            "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒåŸºäºäººå·¥ç¥ç»ç½‘ç»œçš„ç ”ç©¶ã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ æ•°æ®çš„å¤šå±‚æ¬¡è¡¨ç¤ºï¼Œè¿™äº›è¡¨ç¤ºå¯¹åº”äºä¸åŒå±‚æ¬¡çš„æŠ½è±¡ã€‚æ·±åº¦å­¦ä¹ å·²è¢«åº”ç”¨äºè®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸã€‚",
            "filename": "deep_learning.txt",
            "doc_type": "text", 
            "metadata": {"category": "technology", "language": "zh"}
        },
        {
            "id": "doc_4",
            "content": "è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œæ—¨åœ¨è®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€å¤„ç†å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚NLPæŠ€æœ¯åŒ…æ‹¬æ–‡æœ¬åˆ†æã€æœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æã€é—®ç­”ç³»ç»Ÿç­‰åº”ç”¨ã€‚ç°ä»£NLPå¤§é‡ä½¿ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ã€‚",
            "filename": "nlp_intro.txt",
            "doc_type": "text",
            "metadata": {"category": "technology", "language": "zh"}
        }
    ]


class TestRAGSystemBasics:
    """RAGç³»ç»ŸåŸºç¡€åŠŸèƒ½æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_system_initialization(self, rag_system):
        """æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–"""
        assert rag_system.initialized
        
        status = await rag_system.get_system_status()
        assert status["initialized"] is True
        assert "components" in status
        assert status["components"]["document_processor"] is True
    
    @pytest.mark.asyncio  
    async def test_document_addition(self, rag_system, sample_documents):
        """æµ‹è¯•æ–‡æ¡£æ·»åŠ """
        
        # æ·»åŠ æ–‡æ¡£
        results = await rag_system.add_documents(sample_documents)
        
        assert results["total_documents"] == len(sample_documents)
        assert results["processed_chunks"] > 0
        assert len(results["failed_documents"]) == 0
        assert results["processing_time"] > 0
    
    @pytest.mark.asyncio
    async def test_basic_search(self, rag_system, sample_documents):
        """æµ‹è¯•åŸºç¡€æœç´¢åŠŸèƒ½"""
        
        # å…ˆæ·»åŠ æ–‡æ¡£
        await rag_system.add_documents(sample_documents)
        
        # æ‰§è¡Œæœç´¢
        response = await rag_system.search(
            query="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½",
            user_id="test_user",
            top_k=3
        )
        
        assert response.query == "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½"
        assert len(response.results) > 0
        assert len(response.results) <= 3
        
        # æ£€æŸ¥ç»“æœè´¨é‡
        first_result = response.results[0]
        assert first_result.score > 0
        assert "äººå·¥æ™ºèƒ½" in first_result.chunk.content or "AI" in first_result.chunk.content
    
    @pytest.mark.asyncio
    async def test_english_search(self, rag_system, sample_documents):
        """æµ‹è¯•è‹±æ–‡æœç´¢"""
        
        # å…ˆæ·»åŠ æ–‡æ¡£
        await rag_system.add_documents(sample_documents)
        
        # æ‰§è¡Œè‹±æ–‡æœç´¢
        response = await rag_system.search(
            query="What is machine learning",
            user_id="test_user",
            top_k=3
        )
        
        assert len(response.results) > 0
        
        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°ç›¸å…³è‹±æ–‡å†…å®¹
        found_relevant = False
        for result in response.results:
            if "machine learning" in result.chunk.content.lower():
                found_relevant = True
                break
        
        assert found_relevant, "Should find relevant English content"
    
    @pytest.mark.asyncio
    async def test_filtered_search(self, rag_system, sample_documents):
        """æµ‹è¯•è¿‡æ»¤æœç´¢"""
        
        # å…ˆæ·»åŠ æ–‡æ¡£
        await rag_system.add_documents(sample_documents)
        
        # ä½¿ç”¨è¿‡æ»¤å™¨æœç´¢
        response = await rag_system.search(
            query="æ·±åº¦å­¦ä¹ ",
            user_id="test_user",
            top_k=5,
            filters={"language": "zh"}
        )
        
        assert len(response.results) > 0
        
        # éªŒè¯è¿‡æ»¤æ•ˆæœï¼ˆæ³¨æ„ï¼šå½“å‰å®ç°å¯èƒ½ä¸æ”¯æŒè¿‡æ»¤ï¼Œæ‰€ä»¥è¿™æ˜¯é¢„æœŸè¡Œä¸ºï¼‰
        # è¿™ä¸ªæµ‹è¯•ä¸»è¦éªŒè¯è¿‡æ»¤å‚æ•°ä¸ä¼šå¯¼è‡´é”™è¯¯


class TestRAGServiceIntegration:
    """RAGæœåŠ¡é›†æˆæµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_service_initialization(self, rag_service):
        """æµ‹è¯•æœåŠ¡åˆå§‹åŒ–"""
        assert rag_service.rag_system is not None
        
        status = await rag_service.get_system_status()
        assert status.get("initialized") is True
    
    @pytest.mark.asyncio
    async def test_document_upload(self, rag_service):
        """æµ‹è¯•æ–‡æ¡£ä¸Šä¼ """
        
        result = await rag_service.upload_document(
            user_id="test_user",
            filename="test_doc.txt",
            content="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼ŒåŒ…å«ä¸€äº›æµ‹è¯•å†…å®¹ã€‚äººå·¥æ™ºèƒ½æ˜¯æœªæ¥æŠ€æœ¯å‘å±•çš„é‡è¦æ–¹å‘ã€‚",
            doc_type="text",
            metadata={"category": "test"}
        )
        
        assert result["status"] == "processed"
        assert result["chunks_created"] > 0
        assert "document_id" in result
    
    @pytest.mark.asyncio
    async def test_batch_document_upload(self, rag_service, sample_documents):
        """æµ‹è¯•æ‰¹é‡æ–‡æ¡£ä¸Šä¼ """
        
        result = await rag_service.upload_documents_batch(
            user_id="test_user",
            documents=sample_documents
        )
        
        assert result["status"] == "completed"
        assert result["total_documents"] == len(sample_documents)
        assert result["processed_chunks"] > 0
    
    @pytest.mark.asyncio
    async def test_service_query(self, rag_service, sample_documents):
        """æµ‹è¯•æœåŠ¡æŸ¥è¯¢"""
        
        # å…ˆä¸Šä¼ æ–‡æ¡£
        await rag_service.upload_documents_batch("test_user", sample_documents)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        result = await rag_service.query(
            user_id="test_user",
            query="æœºå™¨å­¦ä¹ æ˜¯ä»€ä¹ˆ",
            top_k=3
        )
        
        assert "query" in result
        assert "documents" in result
        assert "metadata" in result
        assert len(result["documents"]) > 0
        
        # æ£€æŸ¥æ–‡æ¡£æ ¼å¼
        doc = result["documents"][0]
        required_fields = ["id", "content", "source", "score", "retrieval_method"]
        for field in required_fields:
            assert field in doc


class TestRAGPerformance:
    """RAGç³»ç»Ÿæ€§èƒ½æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_search_performance(self, rag_system, sample_documents):
        """æµ‹è¯•æœç´¢æ€§èƒ½"""
        
        # æ·»åŠ æ–‡æ¡£
        await rag_system.add_documents(sample_documents)
        
        # æ‰§è¡Œå¤šæ¬¡æœç´¢æµ‹è¯•æ€§èƒ½
        queries = [
            "äººå·¥æ™ºèƒ½çš„åº”ç”¨",
            "What is deep learning",
            "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯",
            "æœºå™¨å­¦ä¹ ç®—æ³•"
        ]
        
        total_time = 0
        for query in queries:
            response = await rag_system.search(
                query=query,
                user_id="test_user",
                top_k=5
            )
            total_time += response.retrieval_time_ms
            
            # éªŒè¯å“åº”æ—¶é—´åˆç†
            assert response.retrieval_time_ms < 5000  # å°äº5ç§’
        
        avg_time = total_time / len(queries)
        print(f"Average search time: {avg_time:.2f}ms")
        assert avg_time < 2000  # å¹³å‡å“åº”æ—¶é—´å°äº2ç§’
    
    @pytest.mark.asyncio
    async def test_concurrent_searches(self, rag_system, sample_documents):
        """æµ‹è¯•å¹¶å‘æœç´¢"""
        
        # æ·»åŠ æ–‡æ¡£
        await rag_system.add_documents(sample_documents)
        
        # å¹¶å‘æ‰§è¡Œå¤šä¸ªæœç´¢
        async def search_task(query_id: int):
            response = await rag_system.search(
                query=f"æµ‹è¯•æŸ¥è¯¢ {query_id}",
                user_id=f"user_{query_id}",
                top_k=3
            )
            return len(response.results)
        
        # åˆ›å»º10ä¸ªå¹¶å‘ä»»åŠ¡
        tasks = [search_task(i) for i in range(10)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # éªŒè¯æ‰€æœ‰ä»»åŠ¡æˆåŠŸå®Œæˆ
        for result in results:
            assert not isinstance(result, Exception), f"Concurrent search failed: {result}"
            assert isinstance(result, int) and result >= 0


class TestRAGErrorHandling:
    """RAGç³»ç»Ÿé”™è¯¯å¤„ç†æµ‹è¯•"""
    
    @pytest.mark.asyncio
    async def test_empty_query(self, rag_system, sample_documents):
        """æµ‹è¯•ç©ºæŸ¥è¯¢å¤„ç†"""
        
        await rag_system.add_documents(sample_documents)
        
        # æµ‹è¯•ç©ºæŸ¥è¯¢
        response = await rag_system.search(
            query="",
            user_id="test_user"
        )
        
        # ç©ºæŸ¥è¯¢åº”è¯¥è¿”å›ç©ºç»“æœæˆ–é»˜è®¤ç»“æœ
        assert len(response.results) >= 0
    
    @pytest.mark.asyncio
    async def test_invalid_documents(self, rag_system):
        """æµ‹è¯•æ— æ•ˆæ–‡æ¡£å¤„ç†"""
        
        invalid_docs = [
            {"id": "invalid_1", "content": ""},  # ç©ºå†…å®¹
            {"id": "invalid_2"},  # ç¼ºå°‘contentå­—æ®µ
            {"id": "invalid_3", "content": None}  # Noneå†…å®¹
        ]
        
        result = await rag_system.add_documents(invalid_docs)
        
        # ç³»ç»Ÿåº”è¯¥èƒ½å¤„ç†æ— æ•ˆæ–‡æ¡£è€Œä¸å´©æºƒ
        assert result["total_documents"] == len(invalid_docs)
        # å¯èƒ½æœ‰å¤±è´¥çš„æ–‡æ¡£
        assert len(result["failed_documents"]) >= 0
    
    @pytest.mark.asyncio
    async def test_system_status_after_error(self, rag_system):
        """æµ‹è¯•é”™è¯¯åç³»ç»ŸçŠ¶æ€"""
        
        # å°è¯•å¤„ç†æ— æ•ˆæ–‡æ¡£
        try:
            await rag_system.add_documents([{"invalid": "document"}])
        except:
            pass
        
        # ç³»ç»Ÿåº”è¯¥ä»ç„¶å¯ç”¨
        status = await rag_system.get_system_status()
        assert status["initialized"] is True


# è¿è¡Œé›†æˆæµ‹è¯•çš„ä¸»å‡½æ•°
async def main():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    
    print("ğŸš€ å¼€å§‹RAGç³»ç»Ÿé›†æˆæµ‹è¯•...")
    
    try:
        # åˆ›å»ºRAGç³»ç»Ÿ
        rag_system = await create_advanced_rag_system(
            vector_store_type="chromadb",
            enable_graph_retrieval=False,  # ç®€åŒ–æµ‹è¯•
            enable_advanced_reranking=False,
            enable_query_expansion=False
        )
        
        print("âœ… RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        
        # å‡†å¤‡æµ‹è¯•æ–‡æ¡£
        sample_docs = [
            {
                "id": "test_doc_1",
                "content": "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œæ·±åº¦å­¦ä¹ æ˜¯å…¶ä¸­çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚",
                "filename": "test1.txt",
                "doc_type": "text"
            }
        ]
        
        # æµ‹è¯•æ–‡æ¡£æ·»åŠ 
        print("ğŸ“„ æµ‹è¯•æ–‡æ¡£æ·»åŠ ...")
        add_result = await rag_system.add_documents(sample_docs)
        print(f"   æ–‡æ¡£æ·»åŠ ç»“æœ: {add_result['processed_chunks']} ä¸ªæ–‡æ¡£å—")
        
        # æµ‹è¯•æœç´¢
        print("ğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½...")
        search_result = await rag_system.search(
            query="äººå·¥æ™ºèƒ½çš„å‘å±•",
            user_id="test_user"
        )
        print(f"   æœç´¢ç»“æœ: {len(search_result.results)} ä¸ªç»“æœ")
        if search_result.results:
            print(f"   æœ€ä½³åŒ¹é…åˆ†æ•°: {search_result.results[0].score:.3f}")
        
        # æµ‹è¯•ç³»ç»ŸçŠ¶æ€
        print("ğŸ“Š æ£€æŸ¥ç³»ç»ŸçŠ¶æ€...")
        status = await rag_system.get_system_status()
        print(f"   ç³»ç»ŸçŠ¶æ€: {'âœ… æ­£å¸¸' if status['initialized'] else 'âŒ å¼‚å¸¸'}")
        
        await rag_system.shutdown()
        print("âœ… RAGç³»ç»Ÿé›†æˆæµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())